{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import h5py\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict = {'good':0, 'holes_cuts':1, 'threaderror':2, 'oilstains_colorerror':3, 'wrinkles':4, 'foreignbodies':5}\n",
    "file_path = r'/home/soucs/Python/textile-defect-inspection/dataset/textile_defect_data.hdF5'\n",
    "images = h5py.File(file_path)['jute_defect_imgs'][:]\n",
    "labels = h5py.File(file_path)['jute_defect_labels'][:]\n",
    "\n",
    "def IMG(i):\n",
    "    return resize_img(images[i])\n",
    "def resize_img(img):\n",
    "    dim = (500, 500)\n",
    "    return cv2.resize(img,dim,interpolation=cv2.INTER_AREA)\n",
    "def show(imgs):\n",
    "    for i, img in enumerate(imgs):\n",
    "        cv2.imshow('img'+str(i),img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "def blur(img,k=5):\n",
    "    ksize = (k,k)\n",
    "    return cv2.blur(img,ksize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIFT\n",
    "\n",
    "* Texture of image giving too many redundant keypoints\n",
    "* Defect part not getting detected in most images\n",
    "* Blurred image results in less no.of kp but not detecting defect at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying SIFT\n",
    "img = blur(IMG(10))\n",
    "sift = cv2.SIFT_create()\n",
    "kp, des = sift.detectAndCompute(img, None)\n",
    "sift_img = cv2.drawKeypoints(img, kp, 0, (0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "show([img,sift_img])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-occurence matrix\n",
    "\n",
    "* Used in svm and giving 45% accuracy appx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "def coMat(img,npx = 32):\n",
    "    converted_image = np.round(img / 255.0 * npx-1).astype(np.uint8)\n",
    "    img = converted_image\n",
    "    # Define the distance and angle offsets for co-occurrence\n",
    "    d = 1\n",
    "    theta = 0\n",
    "    # Compute the co-occurrence matrix\n",
    "    co_mat = np.zeros((npx, npx), dtype=np.uint32)\n",
    "    for i in range(d, img.shape[0]):\n",
    "        for j in range(d, img.shape[1]):\n",
    "            i_index = img[i, j]\n",
    "            j_index = img[i-d, j+theta]\n",
    "            co_mat[i_index, j_index] += 1\n",
    "    # Normalize and return the co-occurrence matrix\n",
    "    co_mat = co_mat.astype(np.float64)\n",
    "    co_mat /= np.sum(co_mat)\n",
    "    return co_mat\n",
    "\n",
    "def glcm(img,npx=32):\n",
    "    converted_image = np.round(img / 255.0 * npx).astype(np.uint8)\n",
    "    img = converted_image\n",
    "    displacement = (1, 0)\n",
    "    num_bins = npx\n",
    "    co_matrix = cv2.calcHist([img, img], [0, 1], None, [num_bins, num_bins], [0, num_bins, 0, num_bins], accumulate=False)\n",
    "    co_matrix_normalized = cv2.normalize(co_matrix, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    return co_matrix_normalized\n",
    "\n",
    "# # Calculate contrast, energy, homogeneity, correlation from glcm\n",
    "# def glcm(img,npx=32):\n",
    "#     converted_image = np.round(img / 255.0 * npx).astype(np.uint8)\n",
    "#     img = converted_image\n",
    "#     displacement = (1, 0)\n",
    "#     num_bins = npx\n",
    "#     co_matrix = cv2.calcHist([img, img], [0, 1], None, [num_bins, num_bins], [0, num_bins, 0, num_bins], accumulate=False)\n",
    "#     co_matrix_normalized = cv2.normalize(co_matrix, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "#     contrast = np.sum((co_matrix_normalized * np.arange(num_bins)[:, np.newaxis] - np.mean(co_matrix_normalized)) ** 2)\n",
    "#     energy = np.sum(co_matrix_normalized ** 2)\n",
    "#     homogeneity = np.sum(co_matrix_normalized / (1 + np.abs(np.arange(num_bins)[:, np.newaxis] - np.arange(num_bins))))\n",
    "#     x, y = np.meshgrid(np.arange(num_bins), np.arange(num_bins))\n",
    "#     correlation = np.sum((co_matrix_normalized * (x - np.mean(x)) * (y - np.mean(y))) / (np.std(x) * np.std(y)))    \n",
    "#     return [contrast, energy, homogeneity, correlation]\n",
    "\n",
    "img = IMG(10)\n",
    "print(coMat(img).shape)\n",
    "print(glcm(img).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laplacian, Canny Edge, Dilation/Erosion\n",
    "\n",
    "* Try dilation to extract defect region\n",
    "* Try Laplacian for same\n",
    "* Try Canny edge for same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply Canny edge detector\n",
    "# edges = cv.Canny(img, 100, 200)\n",
    "# kernel = np.ones((3, 3), np.uint8) # Create 3x3 kernel for dilation\n",
    "# dilated = cv.dilate(edges, kernel, iterations=2) # Dilate edges using kernel\n",
    "\n",
    "# Compute the Laplacian\n",
    "# log = cv.Laplacian(img, cv.CV_64F)\n",
    "# show([img,log])\n",
    "\n",
    "\n",
    "# # Difference of texture tile from img to detect kernel\n",
    "# # Define the kernel\n",
    "# kernel = img[:50,:50]\n",
    "# # kernel_img  = np.tile(kernel, (10, 10))\n",
    "# # result = img-kernel_img\n",
    "\n",
    "# max_li = set()\n",
    "# for i in range(0,450,10):\n",
    "#     for j in range(0,450,10):\n",
    "#         kernel = img[i:50+i,j:50+j]\n",
    "#         max_li.add(coMat(kernel))\n",
    "#         print(i,j)\n",
    "# print(max_li)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavelet\n",
    "\n",
    "* Certain defects, especially wrinkles not getting detected properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = IMG(170)\n",
    "\n",
    "# Perform 2D wavelet transform using Haar wavelet\n",
    "coeffs = pywt.dwt2(img, 'haar')\n",
    "\n",
    "# Split the coefficients into sub-bands\n",
    "cA, (cH, cV, cD) = coeffs\n",
    "\n",
    "# Display the resulting sub-bands\n",
    "cv2.imshow('Img', img)\n",
    "cv2.imshow('Approximation (low-pass)', cA)\n",
    "cv2.imshow('Horizontal detail (high-pass)', cH)\n",
    "cv2.imshow('Vertical detail (high-pass)', cV)\n",
    "cv2.imshow('Diagonal detail (high-pass)', cD)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gray Level Histogram Correlation\n",
    "\n",
    "* Check for patterns in correlation b/w defect and defect-less regions' GLH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the kernel\n",
    "# kernel = img[:50,:50]\n",
    "\n",
    "# # Calculate histogram\n",
    "# hist0 = cv.calcHist([kernel],[0],None,[256],[0,256])\n",
    "# hist1 = cv.calcHist([img[150:200,350:400]],[0],None,[256],[0,256])\n",
    "# show([img])\n",
    "\n",
    "# # Plot histogram\n",
    "# plt.plot(hist0)\n",
    "# plt.plot(hist1)\n",
    "# plt.xlim([0, 256])\n",
    "# plt.xlabel('Gray level')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "# # show([img,kernel,result])\n",
    "\n",
    "# # calculate correlation coefficient between the two distributions\n",
    "# corr_coef = np.corrcoef(hist0.reshape(-1), hist1.reshape(-1))[0, 1]\n",
    "# print(corr_coef)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6    \n",
      "0   1.000000  0.019928  0.688875  0.688876  0.384084  0.088680 -0.125088  \\\n",
      "1   0.019928  1.000000  0.084938  0.084918  0.100814 -0.006650 -0.000049   \n",
      "2   0.688875  0.084938  1.000000  1.000000  0.926884  0.090134  0.004733   \n",
      "3   0.688876  0.084918  1.000000  1.000000  0.926884  0.090134  0.004733   \n",
      "4   0.384084  0.100814  0.926884  0.926884  1.000000  0.062578  0.075802   \n",
      "5   0.088680 -0.006650  0.090134  0.090134  0.062578  1.000000 -0.022459   \n",
      "6  -0.125088 -0.000049  0.004733  0.004733  0.075802 -0.022459  1.000000   \n",
      "7   0.088954 -0.047167  0.045371  0.045372 -0.000681  0.109110 -0.200200   \n",
      "8   0.063308  0.047458  0.028102  0.028101 -0.011015 -0.020704 -0.199599   \n",
      "9   0.033531 -0.035387  0.049471  0.049472  0.054070 -0.021407 -0.200200   \n",
      "10  0.090074 -0.000049  0.028266  0.028266  0.003286 -0.022064 -0.200200   \n",
      "11 -0.150653  0.035289 -0.155886 -0.155887 -0.121485 -0.022518 -0.200200   \n",
      "\n",
      "          7         8         9         10        11  \n",
      "0   0.088954  0.063308  0.033531  0.090074 -0.150653  \n",
      "1  -0.047167  0.047458 -0.035387 -0.000049  0.035289  \n",
      "2   0.045371  0.028102  0.049471  0.028266 -0.155886  \n",
      "3   0.045372  0.028101  0.049472  0.028266 -0.155887  \n",
      "4  -0.000681 -0.011015  0.054070  0.003286 -0.121485  \n",
      "5   0.109110 -0.020704 -0.021407 -0.022064 -0.022518  \n",
      "6  -0.200200 -0.199599 -0.200200 -0.200200 -0.200200  \n",
      "7   1.000000 -0.199599 -0.200200 -0.200200 -0.200200  \n",
      "8  -0.199599  1.000000 -0.199599 -0.199599 -0.199599  \n",
      "9  -0.200200 -0.199599  1.000000 -0.200200 -0.200200  \n",
      "10 -0.200200 -0.199599 -0.200200  1.000000 -0.200200  \n",
      "11 -0.200200 -0.199599 -0.200200 -0.200200  1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# label_dict = {'good':0, 'holes_cuts':1, 'threaderror':2, 'oilstains_colorerror':3, 'wrinkles':4, 'foreignbodies':5}\n",
    "file_path = r'/home/soucs/Python/textile-defect-inspection/dataset/hist_features.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df[['label']]\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(y).toarray()\n",
    "\n",
    "data = np.concatenate([X.values,y],axis=1)\n",
    "\n",
    "correlation_matrix = pd.DataFrame(data).corr()\n",
    "print(correlation_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textile-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
